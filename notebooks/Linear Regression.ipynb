{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import dask_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuml.linear_regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, you will first need to run a dask scheduler and number of dask workers:\n",
    "- Run a dask scheduler with:  ```dask-scheduler --scheduler-file=cluster.json```\n",
    "- Run N dask workers with:  ```mpirun -np N dask-mpi --no-nanny --nthreads 10 --no-scheduler --scheduler-file cluster.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster(threads_per_worker = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numba.cuda\n",
    "\n",
    "# devs = [i.id for i in numba.cuda.cudadrv.devices.gpus]\n",
    "# workers = list(client.has_what().keys())\n",
    "# worker_devs = workers[0:min(len(devs), len(workers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_visible(i, n):\n",
    "#     import os, numba.cuda\n",
    "#     all_devices = list(range(n))\n",
    "#     vd = \",\".join(map(str, all_devices[i:] + all_devices[:i]))\n",
    "#     print(str(vd))\n",
    "# #     numba.cuda.close()\n",
    "# #     numba.cuda.select_device(i)\n",
    "#     print(\"Selecting Device : \"  + str(i))\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = vd\n",
    "\n",
    "# dev_assigned = [client.submit(set_visible, dev, len(devs), workers = [worker]) for dev, worker in zip(devs, worker_devs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = cudf.DataFrame([('a', [0, 1, 2, 3, 4])])\n",
    "y = cudf.Series([0, 1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = dask_cudf.from_cudf(X, chunksize=1).persist()\n",
    "y_df = dask_cudf.from_cudf(y, chunksize=1).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: print_device-3f5ea27f646ee1a43992228b5f876f97>,\n",
       " <Future: status: pending, key: print_device-3f450cfa51e3c56f0456098ebb281dce>,\n",
       " <Future: status: pending, key: print_device-318c2ebda16e8cc49c1553b9b72cd907>,\n",
       " <Future: status: pending, key: print_device-de19f13edf010fd77776266c224d0bd1>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba.cuda\n",
    "import cuml\n",
    "def print_device(arr):\n",
    "    print(str(numba.cuda.get_current_device()))\n",
    "    print(str(cuml.device_of_ptr(arr.as_gpu_matrix(order=\"F\"))))\n",
    "    \n",
    "[client.submit(print_device, part) for part in X_df.to_delayed()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 0)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 1)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 2)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 3)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 0)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 1)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 2)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 3)\": (),\n",
       " 'print_device-318c2ebda16e8cc49c1553b9b72cd907': (),\n",
       " 'print_device-3f450cfa51e3c56f0456098ebb281dce': (),\n",
       " 'print_device-3f5ea27f646ee1a43992228b5f876f97': (),\n",
       " 'print_device-de19f13edf010fd77776266c224d0bd1': ()}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set each worker to host dfs on a different device. \n",
    "\n",
    "__Note__: You can ignore this if you started your workers with \"CUDA_VISIBLE_DEVICE\" already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 0)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 1)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 2)\": (),\n",
       " \"('from_cudf-2748108b4d90493dad42bf02170aa0fe', 3)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 0)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 1)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 2)\": (),\n",
       " \"('from_cudf-769e57f53663474b8598073ed35cf512', 3)\": (),\n",
       " 'print_device-318c2ebda16e8cc49c1553b9b72cd907': (),\n",
       " 'print_device-3f450cfa51e3c56f0456098ebb281dce': (),\n",
       " 'print_device-3f5ea27f646ee1a43992228b5f876f97': (),\n",
       " 'print_device-de19f13edf010fd77776266c224d0bd1': ()}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_devarrays: [(('127.0.0.1', 46201), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-093756d88eb63925908b95436050e63a>), (('127.0.0.1', 45779), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-e582b95a666be250639d6b4b113f2d2c>)]\n",
      "exec_node: ('127.0.0.1', 46201)\n",
      "ipc_handles: [<Future: status: pending, key: get_input_ipc_handles-589c51a26ed26d68e7644914aebe47a2>]\n",
      "raw_arrays: [<Future: status: finished, type: tuple, key: inputs_to_device_arrays-093756d88eb63925908b95436050e63a>]\n"
     ]
    }
   ],
   "source": [
    "res = lr.fit(X_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('127.0.0.1', 46201),\n",
       " <Future: status: finished, type: Series, key: get_result-fddfe99cf522db4e8e017df35c75bbab>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER PARTS: [(('127.0.0.1', 46201), <Future: status: finished, type: DataFrame, key: ('from_cudf-2748108b4d90493dad42bf02170aa0fe', 3)>), (('127.0.0.1', 45779), <Future: status: finished, type: DataFrame, key: ('from_cudf-2748108b4d90493dad42bf02170aa0fe', 0)>), (('127.0.0.1', 46201), <Future: status: finished, type: DataFrame, key: ('from_cudf-2748108b4d90493dad42bf02170aa0fe', 1)>), (('127.0.0.1', 45779), <Future: status: finished, type: DataFrame, key: ('from_cudf-2748108b4d90493dad42bf02170aa0fe', 2)>)]\n",
      "ON WORKER: 2\n",
      "NOT ON WORKER: 2\n",
      "IPCHANDLES = [<Future: status: pending, key: get_ipc_handles-74dcef214b98757381967beb20ff5b9f>, <Future: status: pending, key: get_ipc_handles-7f846146563505420d34042e1845dbfe>]\n",
      "RAW_ARRAYS=[<Future: status: pending, key: as_gpu_matrix-35f93fe34b45823e4241f911d685b2d3>, <Future: status: pending, key: as_gpu_matrix-28b949e9a97f60e5c34e2e24c170870f>]\n",
      "f=<Future: status: finished, type: tuple, key: _predict_on_worker-1543bafb0085a77d103498610a04e3a4>\n"
     ]
    }
   ],
   "source": [
    "g = lr.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tornado.gen.Return(<Future: status: finished, type: Series, key: get_result-1dcbe07e4042802d242dde736d045dca>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuml)",
   "language": "python",
   "name": "cuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
