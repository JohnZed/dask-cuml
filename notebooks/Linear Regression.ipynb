{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, you will first need to run a dask scheduler and number of dask workers:\n",
    "- Run a dask scheduler with:  ```dask-scheduler --scheduler-file=cluster.json```\n",
    "- Run N dask workers with:  ```mpirun -np N dask-mpi --no-nanny --nthreads 10 --no-scheduler --scheduler-file cluster.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to run a cluster internally\n",
    "\n",
    "# from dask_cuda import LocalCUDACluster\n",
    "# cluster = LocalCUDACluster(threads_per_worker = 1)\n",
    "\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you are using an MPI-based cluster\n",
    "client = Client(scheduler_file=\"cluster.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "devs = [0, 1]\n",
    "workers = list(client.has_what().keys())\n",
    "worker_devs = workers[0:min(len(devs), len(workers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_visible(i, n):\n",
    "    import os\n",
    "    all_devices = list(range(n))\n",
    "    vd = \",\".join(map(str, all_devices[i:] + all_devices[:i]))\n",
    "    print(str(vd))\n",
    "    print(\"Selecting Device : \"  + str(i))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = vd\n",
    "    \n",
    "    import numba.cuda\n",
    "    print(\"Cur device: \" + str(numba.cuda.get_current_device().id))\n",
    "    \n",
    "dev_assigned = [client.submit(set_visible, dev, len(devs), workers = [worker]) for dev, worker in zip(devs, worker_devs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import dask_cudf\n",
    "import numba.cuda\n",
    "from dask_cuml.linear_regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Future: status: finished, type: NoneType, key: set_visible-8e4386533916266bf607bb3518c945d4>, <Future: status: finished, type: NoneType, key: set_visible-2202c4a38e62dd9f3d1ca93dd67fd403>]\n"
     ]
    }
   ],
   "source": [
    "print(str(dev_assigned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = cudf.DataFrame([('a', [0, 1, 2, 3, 4])])\n",
    "y = cudf.Series([0, 1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = dask_cudf.from_cudf(X, chunksize=1).persist()\n",
    "y_df = dask_cudf.from_cudf(y, chunksize=1).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set each worker to host dfs on a different device. \n",
    "\n",
    "__Note__: You can ignore this if you started your workers with \"CUDA_VISIBLE_DEVICE\" already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_devarrays: [(('10.2.166.167', 34642), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-3734b60f37801d9c23bd3e7d0744bd09>), (('10.2.166.167', 39157), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-3949c4c7af1de75ca233aafc605e0d10>)]\n",
      "exec_node: ('10.2.166.167', 34642)\n",
      "ipc_handles: [<Future: status: pending, key: get_input_ipc_handles-7f2477bd02cf14719554a66954d47181>]\n",
      "raw_arrays: [<Future: status: finished, type: tuple, key: inputs_to_device_arrays-3734b60f37801d9c23bd3e7d0744bd09>]\n",
      "COEFS: (('10.2.166.167', 39157), <Future: status: pending, key: extract_part-5ec1cf88e22dc20a893cb2eccbdadc05>)\n",
      "INTER: <Future: status: pending, key: extract_part-595c9bb4fa9c7686948eb356635320a4>\n",
      "RES: <Future: status: pending, key: extract_part-595c9bb4fa9c7686948eb356635320a4>\n"
     ]
    }
   ],
   "source": [
    "res = lr.fit(X_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER PARTS: [(('10.2.166.167', 34642), <Future: status: finished, type: DataFrame, key: ('from_cudf-fb4e2715580642c0aaf76d5ff6abf23e', 0)>), (('10.2.166.167', 34642), <Future: status: finished, type: DataFrame, key: ('from_cudf-fb4e2715580642c0aaf76d5ff6abf23e', 2)>), (('10.2.166.167', 39157), <Future: status: finished, type: DataFrame, key: ('from_cudf-fb4e2715580642c0aaf76d5ff6abf23e', 1)>), (('10.2.166.167', 39157), <Future: status: finished, type: DataFrame, key: ('from_cudf-fb4e2715580642c0aaf76d5ff6abf23e', 3)>)]\n",
      "ON WORKER: 2\n",
      "NOT ON WORKER: 2\n",
      "IPCHANDLES = [<Future: status: pending, key: get_ipc_handles-30b13741fd4a49da2dd827f64b75f12c>, <Future: status: pending, key: get_ipc_handles-088e70ad6479fa8338d3f13a709d7d36>]\n",
      "RAW_ARRAYS=[<Future: status: pending, key: as_gpu_matrix-414fb93514c87c433220a2f69fa9a121>, <Future: status: pending, key: as_gpu_matrix-5e393ba1b465a74d19a2de7b3d766887>]\n"
     ]
    }
   ],
   "source": [
    "g = lr.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n"
     ]
    }
   ],
   "source": [
    "print(str(g.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
