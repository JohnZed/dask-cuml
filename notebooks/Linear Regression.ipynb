{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import dask_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuml.linear_regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, you will first need to run a dask scheduler and number of dask workers:\n",
    "- Run a dask scheduler with:  ```dask-scheduler --scheduler-file=cluster.json```\n",
    "- Run N dask workers with:  ```mpirun -np N dask-mpi --no-nanny --nthreads 10 --no-scheduler --scheduler-file cluster.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster(threads_per_worker = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46755\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>20</li>\n",
       "  <li><b>Memory: </b>50.39 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:46755' processes=2 cores=20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "\n",
    "devs = [i.id for i in numba.cuda.cudadrv.devices.gpus]\n",
    "workers = list(client.has_what().keys())\n",
    "worker_devs = workers[0:min(len(devs), len(workers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_visible(i, n):\n",
    "    import os, numba.cuda\n",
    "    all_devices = list(range(n))\n",
    "    vd = \",\".join(map(str, all_devices[i:] + all_devices[:i]))\n",
    "    print(str(vd))\n",
    "    numba.cuda.close()\n",
    "    numba.cuda.select_device(i)\n",
    "    print(\"Selecting Device : \"  + str(i))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = vd\n",
    "\n",
    "dev_assigned = [client.submit(set_visible, dev, len(devs), workers = [worker]) for dev, worker in zip(devs, worker_devs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = cudf.DataFrame([('a', [0, 1, 2, 3, 4])])\n",
    "y = cudf.Series([0, 1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = dask_cudf.from_cudf(X, chunksize=1).persist()\n",
    "y_df = dask_cudf.from_cudf(y, chunksize=1).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: print_device-fa2def07c1ad81017ab2924945106a5c>,\n",
       " <Future: status: pending, key: print_device-c45e4bb6ac7f43dbd4eba609a7b425a0>,\n",
       " <Future: status: pending, key: print_device-34627e871cae334ded4e233cd91406d0>,\n",
       " <Future: status: pending, key: print_device-b1fc434d40eb1e311cbea505670b9a13>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba.cuda\n",
    "import cuml\n",
    "def print_device(arr):\n",
    "    print(str(numba.cuda.get_current_device()))\n",
    "    print(str(cuml.device_of_ptr(arr.as_gpu_matrix(order=\"F\"))))\n",
    "    \n",
    "[client.submit(print_device, part) for part in X_df.to_delayed()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('from_cudf-cd37dc024e134c12a714e9b17461255e', 0)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 1)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 2)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 3)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 0)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 1)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 2)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 3)\": (),\n",
       " 'print_device-34627e871cae334ded4e233cd91406d0': (),\n",
       " 'print_device-b1fc434d40eb1e311cbea505670b9a13': (),\n",
       " 'print_device-c45e4bb6ac7f43dbd4eba609a7b425a0': (),\n",
       " 'print_device-fa2def07c1ad81017ab2924945106a5c': (),\n",
       " 'set_visible-1a0295c5d8555edc245d9f27ca96b873': ('tcp://127.0.0.1:39867',),\n",
       " 'set_visible-3149f083394e13eb32cf2537c871b1a8': ('tcp://127.0.0.1:46701',)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set each worker to host dfs on a different device. \n",
    "\n",
    "__Note__: You can ignore this if you started your workers with \"CUDA_VISIBLE_DEVICE\" already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('from_cudf-cd37dc024e134c12a714e9b17461255e', 0)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 1)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 2)\": (),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 3)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 0)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 1)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 2)\": (),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 3)\": (),\n",
       " 'print_device-34627e871cae334ded4e233cd91406d0': (),\n",
       " 'print_device-b1fc434d40eb1e311cbea505670b9a13': (),\n",
       " 'print_device-c45e4bb6ac7f43dbd4eba609a7b425a0': (),\n",
       " 'print_device-fa2def07c1ad81017ab2924945106a5c': (),\n",
       " 'set_visible-1a0295c5d8555edc245d9f27ca96b873': ('tcp://127.0.0.1:39867',),\n",
       " 'set_visible-3149f083394e13eb32cf2537c871b1a8': ('tcp://127.0.0.1:46701',)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_devarrays: [(('127.0.0.1', 39867), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-35afee8043ed64e2a471d968fd5f5379>), (('127.0.0.1', 46701), <Future: status: finished, type: tuple, key: inputs_to_device_arrays-166f78615428cce0aa9eac5141fb5341>)]\n",
      "exec_node: ('127.0.0.1', 39867)\n",
      "ipc_handles: [<Future: status: pending, key: get_input_ipc_handles-824c00e8925cea052e9f7c882846a100>]\n",
      "raw_arrays: [<Future: status: finished, type: tuple, key: inputs_to_device_arrays-35afee8043ed64e2a471d968fd5f5379>]\n",
      "COEFS: (('127.0.0.1', 39867), <Future: status: pending, key: extract_part-7bc5063212fb7eae4adc886b2ff38e7c>)\n",
      "INTER: <Future: status: pending, key: extract_part-0ba0929262e97ee1f9f195b311354db0>\n",
      "RES: <Future: status: pending, key: extract_part-0ba0929262e97ee1f9f195b311354db0>\n"
     ]
    }
   ],
   "source": [
    "res = lr.fit(X_df, y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"('from_cudf-cd37dc024e134c12a714e9b17461255e', 0)\": ('tcp://127.0.0.1:39867',),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 1)\": ('tcp://127.0.0.1:46701',),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 2)\": ('tcp://127.0.0.1:39867',),\n",
       " \"('from_cudf-cd37dc024e134c12a714e9b17461255e', 3)\": ('tcp://127.0.0.1:46701',),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 0)\": ('tcp://127.0.0.1:39867',),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 1)\": ('tcp://127.0.0.1:46701',),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 2)\": ('tcp://127.0.0.1:39867',),\n",
       " \"('from_cudf-ea58007f60de4e0b875070816af6162b', 3)\": ('tcp://127.0.0.1:46701',),\n",
       " '_fit_on_worker-9c44b51477cd6c40f7578a4c62b40678': (),\n",
       " 'extract_part-0ba0929262e97ee1f9f195b311354db0': ('tcp://127.0.0.1:39867',),\n",
       " 'extract_part-7bc5063212fb7eae4adc886b2ff38e7c': ('tcp://127.0.0.1:39867',),\n",
       " 'get_input_ipc_handles-824c00e8925cea052e9f7c882846a100': (),\n",
       " 'get_result-cfeb9d6fbf537487e79bf6fa5111c539': (),\n",
       " 'inputs_to_device_arrays-166f78615428cce0aa9eac5141fb5341': (),\n",
       " 'inputs_to_device_arrays-35afee8043ed64e2a471d968fd5f5379': (),\n",
       " 'print_device-34627e871cae334ded4e233cd91406d0': ('tcp://127.0.0.1:39867',),\n",
       " 'print_device-b1fc434d40eb1e311cbea505670b9a13': ('tcp://127.0.0.1:46701',),\n",
       " 'print_device-c45e4bb6ac7f43dbd4eba609a7b425a0': ('tcp://127.0.0.1:46701',),\n",
       " 'print_device-fa2def07c1ad81017ab2924945106a5c': ('tcp://127.0.0.1:39867',),\n",
       " 'set_visible-1a0295c5d8555edc245d9f27ca96b873': ('tcp://127.0.0.1:39867',),\n",
       " 'set_visible-3149f083394e13eb32cf2537c871b1a8': ('tcp://127.0.0.1:46701',),\n",
       " 'tuple-2cd7fe3a-eeca-4e32-a5ad-ccb0da944d5b': (),\n",
       " 'tuple-3fddb45f-8df7-4bec-a114-625e941c6ac6': (),\n",
       " 'tuple-b4c855a7-8a6c-40dc-9631-40b8aaeaee45': (),\n",
       " 'tuple-e8fe23d8-a2b2-4894-91e3-4206b76a3b19': ()}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER PARTS: [(('127.0.0.1', 46701), <Future: status: finished, type: DataFrame, key: ('from_cudf-ea58007f60de4e0b875070816af6162b', 3)>), (('127.0.0.1', 39867), <Future: status: finished, type: DataFrame, key: ('from_cudf-ea58007f60de4e0b875070816af6162b', 2)>), (('127.0.0.1', 39867), <Future: status: finished, type: DataFrame, key: ('from_cudf-ea58007f60de4e0b875070816af6162b', 0)>), (('127.0.0.1', 46701), <Future: status: finished, type: DataFrame, key: ('from_cudf-ea58007f60de4e0b875070816af6162b', 1)>)]\n",
      "ON WORKER: 2\n",
      "NOT ON WORKER: 2\n",
      "IPCHANDLES = [<Future: status: pending, key: get_ipc_handles-5b44687ba651d0ffc8fa67274c2e816b>, <Future: status: pending, key: get_ipc_handles-94c595584fbd6789157d7ca78945b46a>]\n",
      "RAW_ARRAYS=[<Future: status: pending, key: as_gpu_matrix-3fe28086efdb6d6c9e9fc61ab1607d78>, <Future: status: pending, key: as_gpu_matrix-2f4c298c0ba4f4c9810fb016dc69db1d>]\n",
      "f=<Future: status: finished, type: tuple, key: _predict_on_worker-2a06e0f3cbf9526c700e3cea5a9ff8db>\n"
     ]
    }
   ],
   "source": [
    "g = lr.predict(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Worker process 62723 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker process 62722 was killed by unknown signal\n",
      "distributed.nanny - ERROR - Failed to restart worker after its process exited\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 291, in _on_exit\n",
      "    yield self.instantiate()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 226, in instantiate\n",
      "    self.process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 370, in start\n",
      "    yield self.process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/process.py\", line 35, in _call_and_set_future\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/process.py\", line 184, in _start\n",
      "    process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/context.py\", line 281, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_forkserver.py\", line 36, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_forkserver.py\", line 52, in _launch\n",
      "    self.sentinel, w = forkserver.connect_to_new_process(self._fds)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/forkserver.py\", line 66, in connect_to_new_process\n",
      "    client.connect(self._forkserver_address)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - ERROR - Failed to restart worker after its process exited\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 291, in _on_exit\n",
      "    yield self.instantiate()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 226, in instantiate\n",
      "    self.process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/nanny.py\", line 370, in start\n",
      "    yield self.process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/tornado/gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"/share/conda/cuml/lib/python3.5/asyncio/futures.py\", line 294, in result\n",
      "    raise self._exception\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/process.py\", line 35, in _call_and_set_future\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/share/conda/cuml/lib/python3.5/site-packages/distributed/process.py\", line 184, in _start\n",
      "    process.start()\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/context.py\", line 281, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_forkserver.py\", line 36, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/popen_forkserver.py\", line 52, in _launch\n",
      "    self.sentinel, w = forkserver.connect_to_new_process(self._fds)\n",
      "  File \"/share/conda/cuml/lib/python3.5/multiprocessing/forkserver.py\", line 66, in connect_to_new_process\n",
      "    client.connect(self._forkserver_address)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    }
   ],
   "source": [
    "print(str(g.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuml)",
   "language": "python",
   "name": "cuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
